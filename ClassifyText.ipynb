{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# The goal of this Jupyter Notebook is to use an LLM for text classification, i.e., for support cases. The idea is to \n",
    "# categorize the support cases and additionally provide a reason for the categorization and also a possible solution \n",
    "# to help and relieve the support team.\n",
    "\n",
    "# See also for advantages and disadvantages of using an LLM to classify text:\n",
    "# https://sarah-packowski.medium.com/when-and-why-would-you-use-an-llm-for-text-classification-94b39ddc2947\n",
    "\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_community.llms import LlamaCpp\n",
    "\n",
    "# We use Llama.cpp for running an LLM locally:\n",
    "# https://python.langchain.com/docs/guides/local_llms\n",
    "# and a model from Mistral AI https://mistral.ai/\n",
    "# Reason: Mistral AI models are open source and are ranked quite good on this leaderboard:\n",
    "# https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard\n",
    "# See also: https://www.reddit.com/r/LocalLLaMA/comments/18hh3qm/best_local_llm_for_german/\n",
    "# https://mistral.ai/news/mixtral-of-experts/ (too slow on my laptop but better than Mistral-7B)\n",
    "# https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2\n",
    "# https://huggingface.co/TheBloke (LLM: quantisation, fine tuning)\n",
    "# https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF (we need the new GGUF format)\n",
    "llm = LlamaCpp(\n",
    "    model_path=R\"C:\\Users\\WernerGaisbauer\\LLMs\\mistral-7b-instruct-v0.2.Q4_K_M.gguf\",\n",
    "    n_gpu_layers=1,\n",
    "    n_batch=512,\n",
    "    n_ctx=2048,\n",
    "    f16_kv=True,\n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "#llm(\"The first man on the moon was ... Let's think step by step\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "751796e481fe5ac9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# For testing, we use a bunch of German support cases.\n",
    "# https://www.kaggle.com/datasets/jordanrich/german-emails-in-xml\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"archive/German_emails.csv\")\n",
    "print(df.shape)\n",
    "print(df.columns.tolist())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19a7ac632f5f064",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Loop over the DataFrame's rows.\n",
    "for index, row in df.iterrows():\n",
    "    # Access each column by its name, e.g., row['name'], row['age'], row['city']\n",
    "    print(f\"id: {row['id']}, category: {row['category']}, text: {row['text']}, relevantText: {row['relevantText']}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84061def734bd3c3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Convert rows to a dictionary.\n",
    "n = 1\n",
    "row1_dict = df.iloc[n].to_dict()\n",
    "#print(row1_dict)\n",
    "support_email1 = row1_dict[\"relevantText\"]\n",
    "print(n)\n",
    "print(support_email1)\n",
    "\n",
    "n = 6\n",
    "row6_dict = df.iloc[n].to_dict()\n",
    "#print(row6_dict)\n",
    "support_email2 = row6_dict[\"relevantText\"]\n",
    "print(n)\n",
    "print(support_email2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e77c08b08cd38c6a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# https://learn.deeplearning.ai/langchain/lesson/2/models,-prompts-and-parsers\n",
    "# See section Parse the LLM output string into a Python dictionary.\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12a63bcccebfa9cd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "kategorien = \"\"\"Data Warehouse, Technischer Support, Rechnungsprobleme, Kontoverwaltung, Feedback, Andere Anfragen\"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a022c8fea9c2e1a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "kategorie_schema = ResponseSchema(name=\"kategorie\", description=f\"Ordne die Anfrage einer der vorgegebenen Kategorien\"\n",
    "                                                                f\" zu: {kategorien}.\")\n",
    "begruendung_schema = ResponseSchema(name=\"begruendung\", description=\"Gib für die Zuordnung eine kurze Begründung an, \"\n",
    "                                                                    \"um die Entscheidung zu erklären.\")\n",
    "loesungsvorschlag_schema = ResponseSchema(name=\"loesungsvorschlag\", description=\"Gib einen Lösungsvorschlag für die \"\n",
    "                                                                                \"Support-Anfrage an.\")\n",
    "\n",
    "response_schemas = [kategorie_schema, \n",
    "                    begruendung_schema,\n",
    "                    loesungsvorschlag_schema]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96e5e897ce6dbd5b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac65c35845242e97",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d7e671650848fd4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(format_instructions)\n",
    "# Unfortunately, the instructions are in English, but we need German instructions, therefore we build the \n",
    "# instructions manually below.\n",
    "# It seems that there is no localisation out of the box available:\n",
    "# https://github.com/langchain-ai/langchain/issues/5203"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f4e9f46a66373a7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94eeac386d658c55",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "format_instructions = f\"\"\"Die Ausgabe sollte ein Markdown-Code-Snippet sein, formatiert nach dem folgenden Schema, \n",
    "einschließlich der führenden und abschließenden \"\\`\\`\\`json\" und \"\\`\\`\\`\":\n",
    "\n",
    "```json\n",
    "{{\n",
    "\t\"kategorie\": string  // Ordne die Anfrage einer der vorgegebenen Kategorien zu: {kategorien}.\n",
    "\t\"begruendung\": string  // Gib für die Zuordnung eine kurze Begründung an, um die Entscheidung zu erklären.\n",
    "\t\"loesungsvorschlag\": string  // Gib einen Lösungsvorschlag für die Support-Anfrage an.\n",
    "}}\n",
    "```\"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83e206002399782",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "template_string = \"\"\"\\\n",
    "Bitte lies dir die folgende Support-Anfrage sorgfältig durch und erstelle folgende Informationen:\n",
    "\n",
    "kategorie: Ordne die Anfrage einer der vorgegebenen Kategorien zu: {kategorien}.\n",
    "begruendung: Gib für die Zuordnung eine kurze Begründung an, um die Entscheidung zu erklären.\n",
    "loesungsvorschlag: Gib einen Lösungsvorschlag für die Support-Anfrage an.\n",
    "\n",
    "Support-Anfrage: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=template_string)\n",
    "\n",
    "messages = prompt.format_messages(text=support_email1,\n",
    "                                  format_instructions=format_instructions,\n",
    "                                  kategorien=kategorien)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fe65dff6f232bac",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(messages[0].content)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b301f99705bdcba",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "response = llm(messages[0].content)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6debdd1ae768108e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(response)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa809a285b8da4ed",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "output_dict = output_parser.parse(response)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79b59f56341a7316",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "output_dict"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b046eb4a40da70d0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "type(output_dict)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b02a4b4113695d5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "output_dict.get('kategorie')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e06a5809711bbce",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
